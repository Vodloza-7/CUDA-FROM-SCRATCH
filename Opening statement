from scratch so this is what i know abouT cuda so far...lets not use AI please ..learn from scratch

1. in relation to parallel computing and GPU"S
   2.NVIDIA machines
   3.GPGPU which are GPUS but used for general purpose tasks
   4.The CUDA programming language is low level or close and it allows the manipulation of these powerful GPU'S

Having gone through the first chapter of that [CUDA Programming guide](https://docs.nvidia.com/cuda/cuda-programming-guide/index.html) by NVIDIA, I would like to start by saying the theory was mind boggling and the time to cover it was a bit somewhat limited (Not that I complain or anything). There was a mouthful to learn and as someone who was completely new to the field with just an interest in coding, often it could get boring having to sort of force the new terminologies and concepts into my tiny head, lol; but there is pretty much a handful I have managed to grasp. I will just try to highlighlight some of it in form topic heaings below, and then as time progresses and the spirit leading me, I might expand on these topics a bit.

## PROGRAMMING MODEL

1. Heterogenous Systems
2. GPU Hardware MOdel
3. GPU Memory

## CUDA PLATFORM

1. Compute Compatibility and Streaming Multiprocessor (SM)
2. GPU Driver and CUDA Toolkit
3. PTX (Parallel Threading Execution)
4. Cubins and Fatbins
5. JIT (Just-In-Time) Compilation Compartibility

For now, I put aside the theory; Moving on to the practical... _Aluta Continua_ ðŸ¤Ÿ

Cupy was a great way to introduce things practically!  
It made me believe for a moment, yeah, I get it.

Two major points I sure couldn't have missed:

1. Use asarray() method of the cupy library when wating to transfer data from the **Host** to the **Device**. To this method, you need to pass as an augumnet the data/array that is to be sent from the CPU to the GPU.
2. Use asnumpy() method of the cupy library still, when wanting to do the opposite of what is stated above. NB: As an augument to this method, you are to pass the array, which often times needs to be modified from the computation(s) on the GPU (i.e. used on by methods like fftn of the fft module).  
   Both these methods would be taking in arguments the arrays to be transfered from one of the two parts of this herogenous system, to the other. As can should be expected, the array to be taken in by the first, must be of that from the cpu, while the opposite is true about the latter array.  
   Special point also worth mentioning is that, it is advisable to just go ahead and create your data (array) on the Device, instead of creating it on the host, only to just then move it the Device where it is actually going to be manipulated.

FFTs are still a bit unclear to me.
As someone who doesn't have any data science experience, the numpys and scipys are also a bit new to me, althouh where of better solubiity in the tutorial video.

Last but certainly not least. The `%%timeit` magic command, was and continues to be a very handy tool of sometimes gettting to see real in action the beauty and powerfulness of parallel computing which is offered by the gpu as opposed to the CPU's serial execution.

Aluta Continua my fellow commrad..!

### Oh... our dear precious `%%timeit` magic commandðŸ˜£â€¼

Rember how I confidently mentioned this "_handy, powerful_" tool that allows for us to see some result that paint us a bit on the picture of on the beauty and powerfulness of parallel computing, turns out there is potentially some downside to using it (this magic command) sometimes.  
I have said it a bit on the open issue. **The `%%timeit` magic command creates an isolated scope for timing purpose(s).** **Any variables created or modified in the code, underneath it are discarded once the timing is complete.**

This accurately means that when applying the magic command, one should always becareful to not then want to use the **only** modified or created variables under that `%%timeit` command. This may result in wrong results if the program does execute without any runtime errors (like `NameError` haha).

I hate that it's slowly starting to feel and seem like using our beloved `%%timeit` magic command, would afterall prove not to be that advantageous, ayðŸ˜«.

With numba:

1. To send data from the **CPU** to the **GPU**, we use cuda's `todevice()` method where we pass to it as an argument, the array/data to be sent over to the GPU from CPU. This method is accesisible through the _dot notation_.
2. To get back data from the **GPU**, to the **CPU**, we use the `copy_to_host()` method, with _no auguments_ passed to it, and is accessible therefore through the _dot notation_ on the object Device array object.  
   `Cuda` Module can be made available from the `numba` library from an _import statement_.  
   cupy can still be used on a numba.cuda array to create a Device ready array. **NB: Numba wil still work perfectly fine on the cupy arrays.**

Yah!  
The struggle is real for sure! But even if that may become the case, I will not cease to bring us good resource matrial from our dear sister Google the internet.  
Enter: [Numba Python Notes](https://nyu-cds.github.io/python-numba/05-cuda/) to try and ease the pain as we try and make sense of these threads and effective gpu utilization in practice.  
Aluta Continua..!
